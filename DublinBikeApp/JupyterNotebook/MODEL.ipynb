{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from patsy import dmatrices\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "pd.set_option('display.max_columns', None)  \n",
    "def makePrediction(stationNumber):\n",
    "    #read in databases\n",
    "    chart1 = requests.get(\"http://localhost:5000/chartData/\"+stationNumber)\n",
    "    chart2 = requests.get(\"http://localhost:5000/pastWeather\")\n",
    "    #load as json\n",
    "    mainJson = json.loads(chart1.text)\n",
    "    weatherJson=json.loads(chart2.text)\n",
    "\n",
    "    #flatten the weather json\n",
    "    dayofyear=[]\n",
    "    description=[]\n",
    "    weekday=[]\n",
    "    hour=[]\n",
    "    for i in weatherJson['dayofyear']:\n",
    "        dayofyear.append(weatherJson['dayofyear'][i])\n",
    "\n",
    "    for i in weatherJson['description']:\n",
    "        description.append(weatherJson['description'][i])\n",
    "\n",
    "    for i in weatherJson['weekday']:\n",
    "        weekday.append(weatherJson['weekday'][i])\n",
    "\n",
    "    for i in weatherJson['hour']:\n",
    "        hour.append(weatherJson['hour'][i])\n",
    "    weatherDict={}\n",
    "    weatherDict['Dayofyear']= dayofyear\n",
    "    weatherDict['description'] = description\n",
    "    weatherDict['hour']=hour\n",
    "\n",
    "    available_bikes=[]\n",
    "    mainDayofyear=[]\n",
    "    weekday=[]\n",
    "    hour=[]\n",
    "    for i in mainJson['available_bikes']:\n",
    "        available_bikes.append(mainJson['available_bikes'][i])\n",
    "\n",
    "    for i in mainJson['dayofyear']:\n",
    "        mainDayofyear.append(mainJson['dayofyear'][i])\n",
    "\n",
    "    for i in mainJson['weekday']:\n",
    "        weekday.append(mainJson['weekday'][i])\n",
    "\n",
    "    for i in mainJson['hour']:\n",
    "        hour.append(mainJson['hour'][i])\n",
    "\n",
    "\n",
    "    #append to dict, for making dataframe\n",
    "\n",
    "    mainDict = {}\n",
    "    mainDict['Dayofyear']= mainDayofyear\n",
    "    mainDict['availableBikes']= available_bikes\n",
    "    mainDict['weekday']= weekday\n",
    "    mainDict['hour']=hour\n",
    "\n",
    "    #change types for join\n",
    "    mainDf = pd.DataFrame.from_dict(mainDict)\n",
    "    mainDf['Dayofyear']=mainDf['Dayofyear'].astype(float)\n",
    "    mainDf.drop_duplicates()\n",
    "    mainDf.reset_index(drop=True)\n",
    "    mainDf.dtypes\n",
    "\n",
    "    # drop duplicates that share an hour and day \n",
    "    weatherDf=pd.DataFrame.from_dict(weatherDict)\n",
    "    weatherDf.drop_duplicates()\n",
    "    weatherDf= weatherDf.drop_duplicates(['hour','Dayofyear'])\n",
    "\n",
    "    #change types for merging the two tables\n",
    "    weatherDf['Dayofyear']=weatherDf['Dayofyear'].astype(str)\n",
    "    weatherDf['hour']=weatherDf['hour'].astype(str)\n",
    "    weatherDf['period'] = weatherDf[['Dayofyear', 'hour']].apply(lambda x: ''.join(x), axis=1)\n",
    "\n",
    "    #change data types to allow merging tables\n",
    "    mainDf['hour']=mainDf['hour'].astype(float)\n",
    "    mainDf.head()\n",
    "    mainDf['Dayofyear']=mainDf['Dayofyear'].astype(str)\n",
    "    mainDf['hour']=mainDf['hour'].astype(str)\n",
    "    mainDf['period'] = mainDf[['Dayofyear', 'hour']].apply(lambda x: ''.join(x), axis=1)\n",
    "\n",
    "    newMain= mainDf.groupby([mainDf[\"Dayofyear\"],mainDf['period'],mainDf['weekday'], mainDf[\"hour\"]]).mean().round()\n",
    "\n",
    "    newMain.reset_index(inplace=True)\n",
    "\n",
    "    # merge tables\n",
    "    newdf= pd.merge(newMain, weatherDf, how='right', left_on='period', right_on = 'period')\n",
    "\n",
    "    # drop duplicate columns and period column\n",
    "    newdf = newdf.drop('hour_y', 1)\n",
    "    newdf = newdf.drop('period', 1)\n",
    "    newdf = newdf.drop('Dayofyear_y', 1)\n",
    "\n",
    "    # tidy up data types and names\n",
    "    newdf['dayOfYear']=newdf['Dayofyear_x'].astype(float)\n",
    "    newdf['availableBikes']=newdf['availableBikes'].astype(float)\n",
    "    newdf['hour']=newdf['hour_x'].astype(float)\n",
    "    newdf = newdf.drop('hour_x', 1)\n",
    "    newdf = newdf.drop('Dayofyear_x', 1)\n",
    "    newdf.head()\n",
    "\n",
    "    # remove all NaN columsn from target feature\n",
    "    newdf = newdf[np.isfinite(newdf['availableBikes'])]\n",
    "\n",
    "    # set categorical features\n",
    "    newdf['description'].astype('category')\n",
    "    newdf.dtypes\n",
    "    newdf = newdf[newdf.description !='light shower snow']\n",
    "    newdf = newdf[newdf.description !='description_light snow']\n",
    "    \n",
    "    #Start training Model\n",
    "\n",
    "    # decided not to use dayofyear as a continuous feature\n",
    "    df_cont_feat = newdf[['hour']]\n",
    "    df_dummies_weekday = pd.get_dummies(newdf[['weekday']])\n",
    "    df_dummies_weather=pd.get_dummies(newdf[['description']])\n",
    "\n",
    "    # Add dummies to the other continuous features\n",
    "    X = pd.concat([df_cont_feat, df_dummies_weekday, df_dummies_weather], axis =1)\n",
    "    y = newdf[['availableBikes']]\n",
    "\n",
    "    # Train RF with 100 trees\n",
    "    rfc = RandomForestClassifier(n_estimators=1000, max_features='auto', oob_score=True, random_state=1)\n",
    "    # Fit model on full dataset\n",
    "    rfc.fit(X, y)\n",
    "\n",
    "    return joblib.dump(rfc, 'static/'stationNumber+'prediction.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminhowarth/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "predictionWeather = requests.get(\"http://localhost:5000/weather\")\n",
    "\n",
    "predictionWeather = json.loads(predictionWeather.text)\n",
    "\n",
    "for i in predictionWeather['weatherlist']:\n",
    "    forecastDescription.append(i['description'])\n",
    "    forecastDescription.append(i['description'])\n",
    "    forecastDescription.append(i['description'])\n",
    "for i in predictionWeather['weatherlist']:\n",
    "    dt.append(int(i['dt']))\n",
    "    dt.append(int(i['dt'])+3600)\n",
    "    dt.append(int(i['dt'])+7200)\n",
    "predictionWeather={}\n",
    "predictionWeather['dt']=dt\n",
    "predictionWeather['description']=forecastDescription\n",
    "\n",
    "forecastDf = pd.DataFrame.from_dict(predictionWeather)\n",
    "forecastDf.head()\n",
    "\n",
    "forecastDf['dt'] =  pd.to_datetime((forecastDf['dt']), unit='s')\n",
    "forecastDf['weekday'] = forecastDf['dt'].dt.weekday_name\n",
    "forecastDf['hour'] = forecastDf['dt'].dt.hour\n",
    "forecastDf.drop('dt', axis=1, inplace=True)\n",
    "forecastDf.head()\n",
    "\n",
    "# Prepare the data, turn categorical feature  into dummies.\n",
    "# decided not to use dayofyear as a continuous feature\n",
    "prediction_dummies_weekday = pd.get_dummies(forecastDf[['weekday']])\n",
    "prediction_dummies_weather=pd.get_dummies(forecastDf[['description']])\n",
    "\n",
    "currentOrder = prediction_dummies_weekday.columns.tolist()\n",
    "idealOrder = df_dummies_weekday.columns.tolist()\n",
    "for i in idealOrder:\n",
    "    if i not in currentOrder:\n",
    "        prediction_dummies_weekday[i]=0\n",
    "prediction_dummies_weekday= prediction_dummies_weekday[idealOrder]\n",
    "\n",
    "\n",
    "currentWeather=prediction_dummies_weather.columns.tolist()\n",
    "idealWeather= df_dummies_weather.columns.tolist()\n",
    "for i in idealWeather:\n",
    "    if i not in currentWeather:\n",
    "        prediction_dummies_weather[i]=0\n",
    "prediction_dummies_weather=prediction_dummies_weather[idealWeather]\n",
    "\n",
    "forecast = pd.concat([forecastDf['hour'], prediction_dummies_weekday, prediction_dummies_weather], axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = joblib.load('forecastModel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
